{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amzad-786githumb/AI_and_ML_by-Microsoft/blob/main/25_Implementing_deep_learning_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-KFvnGn-kqA"
      },
      "source": [
        "<h2>Tasks:</h2>\n",
        "\n",
        "*  Implement and train models using FNN, CNN, and RNN architectures.\n",
        "\n",
        "*  Compare the performance of each architecture on different types of data.\n",
        "\n",
        "*  Gain hands-on experience using TensorFlow’s Keras API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hky6lVDu-7Te"
      },
      "source": [
        "<h3>Step 1: Set up the environment</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73W7Ux0299Lw",
        "outputId": "1d7cfd78-65fa-4479-f590-fdcdfd57c398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aS1N0qyx_G5z"
      },
      "outputs": [],
      "source": [
        "#Importing the required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z135X93f_WmL"
      },
      "source": [
        "<h3>Step 2: Implement a feedforward neural network (FNN)</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljORRBMZA5Gr"
      },
      "source": [
        "<b>1. Load the Iris dataset</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCt34KKw_VO4"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encode labels\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvr5Z0gNA92j"
      },
      "source": [
        "<b>2. Define the FNN architecture</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAKJXu-2_RkR",
        "outputId": "74aa4760-528c-41b0-8e6c-6f0c66781f77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Build the FNN model\n",
        "model_fnn = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')  # 3 output classes for the Iris dataset\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-yyxz-rByG6"
      },
      "source": [
        "<b>3. Compile and train the model</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p5UTM29Bn9e",
        "outputId": "074855bc-6b80-479c-ed97-a40b2ec93e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - Accuracy: 0.5479 - loss: 1.5459 - val_Accuracy: 0.3333 - val_loss: 1.3359\n",
            "Epoch 2/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - Accuracy: 0.3187 - loss: 1.2919 - val_Accuracy: 0.3333 - val_loss: 1.1339\n",
            "Epoch 3/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - Accuracy: 0.3396 - loss: 1.0758 - val_Accuracy: 0.3333 - val_loss: 1.0025\n",
            "Epoch 4/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - Accuracy: 0.4415 - loss: 0.9743 - val_Accuracy: 0.7000 - val_loss: 0.9276\n",
            "Epoch 5/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - Accuracy: 0.6915 - loss: 0.9151 - val_Accuracy: 0.7000 - val_loss: 0.8916\n",
            "Epoch 6/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - Accuracy: 0.6196 - loss: 0.9242 - val_Accuracy: 0.7000 - val_loss: 0.8567\n",
            "Epoch 7/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - Accuracy: 0.6800 - loss: 0.8508 - val_Accuracy: 0.7000 - val_loss: 0.8223\n",
            "Epoch 8/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - Accuracy: 0.6056 - loss: 0.8385 - val_Accuracy: 0.7333 - val_loss: 0.7961\n",
            "Epoch 9/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - Accuracy: 0.7342 - loss: 0.7919 - val_Accuracy: 0.7333 - val_loss: 0.7655\n",
            "Epoch 10/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - Accuracy: 0.7681 - loss: 0.7515 - val_Accuracy: 0.7667 - val_loss: 0.7312\n",
            "Epoch 11/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - Accuracy: 0.7219 - loss: 0.7401 - val_Accuracy: 0.7667 - val_loss: 0.6986\n",
            "Epoch 12/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - Accuracy: 0.6863 - loss: 0.6834 - val_Accuracy: 0.7000 - val_loss: 0.6683\n",
            "Epoch 13/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - Accuracy: 0.6685 - loss: 0.6697 - val_Accuracy: 0.7000 - val_loss: 0.6430\n",
            "Epoch 14/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - Accuracy: 0.6785 - loss: 0.6509 - val_Accuracy: 0.8000 - val_loss: 0.6216\n",
            "Epoch 15/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - Accuracy: 0.8710 - loss: 0.6097 - val_Accuracy: 0.9000 - val_loss: 0.6021\n",
            "Epoch 16/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - Accuracy: 0.9267 - loss: 0.5857 - val_Accuracy: 0.9333 - val_loss: 0.5779\n",
            "Epoch 17/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - Accuracy: 0.9321 - loss: 0.5628 - val_Accuracy: 0.8000 - val_loss: 0.5462\n",
            "Epoch 18/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - Accuracy: 0.8054 - loss: 0.5616 - val_Accuracy: 0.8000 - val_loss: 0.5211\n",
            "Epoch 19/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - Accuracy: 0.8325 - loss: 0.5301 - val_Accuracy: 0.9333 - val_loss: 0.5034\n",
            "Epoch 20/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - Accuracy: 0.9192 - loss: 0.5130 - val_Accuracy: 0.9667 - val_loss: 0.4894\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bc120c23620>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Compile the model\n",
        "model_fnn.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['Accuracy'])\n",
        "\n",
        "#train the model\n",
        "model_fnn.fit(X_train, y_train, epochs=20, batch_size =32, validation_data =(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCPh7euOJZPV"
      },
      "source": [
        "<b>4. Expected output FNN</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuMLBNT1JjC0",
        "outputId": "e6bf0b2c-b691-4b23-d541-ee986d3ece81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - Accuracy: 0.9667 - loss: 0.4894\n",
            "Test Accuracy: 0.9666666388511658\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model_fnn.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nopRi_voCxs6"
      },
      "source": [
        "<h3>Step 3: Implement a convolutional neural network (CNN)</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzNZtCPIC3wa"
      },
      "source": [
        "<b>1. Load the CIFAR-10 dataset</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ivb7oLFCkYK"
      },
      "outputs": [],
      "source": [
        "#Load CIFAR-10 Dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "#normalize the pixel values\n",
        "train_images = train_images/ 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS-04GvODnCN"
      },
      "source": [
        "<b>2. Define the CNN architecture</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC8Hv5sEDiRh",
        "outputId": "8cafa70c-8f27-4289-94ee-f2415b5940e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#Build the CNN model\n",
        "\n",
        "model_cnn = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rumXo5ZDFEb6"
      },
      "source": [
        "<b>3. Compile and train the model</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1AiRROBE6rv",
        "outputId": "16f8279d-e47e-4cfd-cbc5-a2c125d7e54a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 84ms/step - Accuracy: 0.3522 - loss: 1.7845 - val_Accuracy: 0.5325 - val_loss: 1.3212\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 87ms/step - Accuracy: 0.5586 - loss: 1.2454 - val_Accuracy: 0.6130 - val_loss: 1.1401\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 80ms/step - Accuracy: 0.6230 - loss: 1.0841 - val_Accuracy: 0.6390 - val_loss: 1.0422\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 79ms/step - Accuracy: 0.6542 - loss: 0.9924 - val_Accuracy: 0.6534 - val_loss: 1.0028\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 74ms/step - Accuracy: 0.6728 - loss: 0.9479 - val_Accuracy: 0.6635 - val_loss: 0.9678\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - Accuracy: 0.6966 - loss: 0.8802 - val_Accuracy: 0.6514 - val_loss: 1.0131\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 77ms/step - Accuracy: 0.7050 - loss: 0.8523 - val_Accuracy: 0.6771 - val_loss: 0.9469\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 76ms/step - Accuracy: 0.7249 - loss: 0.8003 - val_Accuracy: 0.6744 - val_loss: 0.9425\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 75ms/step - Accuracy: 0.7364 - loss: 0.7586 - val_Accuracy: 0.6752 - val_loss: 0.9475\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 79ms/step - Accuracy: 0.7459 - loss: 0.7266 - val_Accuracy: 0.6856 - val_loss: 0.9119\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bc120ccc6e0>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#compile the model\n",
        "model_cnn.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['Accuracy'])\n",
        "\n",
        "#Fit the model\n",
        "model_cnn.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPdmxUB0JruE"
      },
      "source": [
        "<b>4.Expected outcome CNN <b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LBHWMWvTJxYb",
        "outputId": "d48b85b5-098b-4349-9d49-64f5ae4146c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - Accuracy: 0.6885 - loss: 0.9112\n",
            "Test Accuracy: 0.6855999827384949\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model_cnn.evaluate(test_images, test_labels)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNdrEx7-Fv6u"
      },
      "source": [
        "<h3>Step 4: Implement a recurrent neural network (RNN)</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXZex-48F_Eh"
      },
      "source": [
        "<b>1. Create synthetic sequential data for a sine wave</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nwVkLvGuFrN6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "##Generate synthetic sine wave\n",
        "t = np.linspace(0, 100, 10000)\n",
        "X = np.sin(t).reshape(-1,1)\n",
        "\n",
        "#prepare sequences\n",
        "def create_sequences(data, seq_length):\n",
        "  X_seq, y_seq =[], []\n",
        "  for i in range(len(data)- seq_length):\n",
        "    X_seq.append(data[i:i+seq_length])\n",
        "    y_seq.append(data[i+seq_length])\n",
        "  return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "seq_length = 10\n",
        "X_seq, y_seq = create_sequences(X, seq_length)\n",
        "\n",
        "#Split the data into training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bU6EfRgHqZT"
      },
      "source": [
        "<b>2. Define the RNN architecture</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GHh5Y23JHkxW",
        "outputId": "8d96813e-5754-4e86-c2f1-cdee5cb1fc9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Build the RNN model\n",
        "model_rnn = models.Sequential([\n",
        "    layers.SimpleRNN(128, input_shape=(seq_length, 1)),\n",
        "    layers.Dense(1)  # Output is a single value (next point in the sequence)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHT9J3vkIFUW"
      },
      "source": [
        "<b>3. Compile and train the model</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "grraoQF5IF_-",
        "outputId": "de0b9b54-087a-45e4-8491-ee00f70defa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0418 - val_loss: 8.7936e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.9023e-05 - val_loss: 1.3120e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.3099e-05 - val_loss: 8.9839e-06\n",
            "Epoch 4/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.8172e-06 - val_loss: 9.0909e-06\n",
            "Epoch 5/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.0132e-05 - val_loss: 1.1668e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0815e-05 - val_loss: 8.0694e-06\n",
            "Epoch 7/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.3282e-06 - val_loss: 5.0327e-06\n",
            "Epoch 8/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.7984e-05 - val_loss: 8.5865e-06\n",
            "Epoch 9/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.8719e-06 - val_loss: 7.7903e-06\n",
            "Epoch 10/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.2460e-05 - val_loss: 4.8249e-06\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bc1093b5790>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compile the model\n",
        "model_rnn.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model_rnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu14HpwzJ6zJ"
      },
      "source": [
        "<b>4.Expected outcome RNN</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p0dRPKOHJ_AT",
        "outputId": "88c086f2-a332-4f99-dee6-6cf880b1ed11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8975e-06\n",
            "Test MSE: 4.8248525672534015e-06\n"
          ]
        }
      ],
      "source": [
        "mse = model_rnn.evaluate(X_test, y_test)\n",
        "print(f'Test MSE: {mse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3r5EBoSIQ9W"
      },
      "source": [
        "<h3>Step 5: Compare performance</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJsjru9jJAM-"
      },
      "source": [
        "*  **FNN:** you should have achieved more than 90 percent accuracy on the Iris dataset, showcasing that FNNs are well-suited for simple classification tasks.\n",
        "\n",
        "*  **CNN:** the CNN should have achieved around 70–80 percent accuracy on the CIFAR-10 dataset, highlighting the CNN’s ability to recognize spatial features in image data.\n",
        "\n",
        "* **RNN:** the RNN should have minimized MSE for predicting the sine wave, demonstrating the RNN's capacity for handling sequential data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl5PgEdbJJjc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNj9uwiLKKpIr78xlQ4T5tD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}