{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPt+fk69+k2Igl7sCd3/0Ky",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amzad-786githumb/AI_and_ML_by-Microsoft/blob/main/27_LLM_fine_tuning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Tasks:</h2>\n",
        "\n",
        "*  Prepare and split task-specific datasets.\n",
        "\n",
        "*  Set up an Azure environment for fine-tuning LLMs.\n",
        "\n",
        "*  Fine-tune a pretrained model for sentiment classification.\n",
        "\n",
        "*  Evaluate and deploy the model for real-time sentiment analysis.\n",
        "\n",
        "*  Interpret evaluation metrics like accuracy and F1 score.\n",
        "\n"
      ],
      "metadata": {
        "id": "yGvpvRK5SmU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Step 1: Prepare the dataset</h3>"
      ],
      "metadata": {
        "id": "hIWvuq6rTL4N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Kay9gi8ZIQZt"
      },
      "outputs": [],
      "source": [
        "#import the required libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Create a noisy dataset\n",
        "data_dict = {\n",
        "    \"text\": [\n",
        "        \"  The staff was very kind and attentive to my needs!!!  \",\n",
        "        \"The waiting time was too long, and the staff was rude. Visit us at http://hospitalreviews.com\",\n",
        "        \"The doctor answered all my questions...but the facility was outdated.   \",\n",
        "        \"The nurse was compassionate & made me feel comfortable!! :) \",\n",
        "        \"I had to wait over an hour before being seen.  Unacceptable service! #frustrated\",\n",
        "        \"The check-in process was smooth, but the doctor seemed rushed. Visit https://feedback.com\",\n",
        "        \"Everyone I interacted with was professional and helpful.  \"\n",
        "    ],\n",
        "    \"label\": [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\", \"positive\"]\n",
        "}\n",
        "\n",
        "#convert data to dataframe\n",
        "data = pd.DataFrame(data_dict)\n",
        "\n",
        "# Clean the text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "    return text\n",
        "\n",
        "\n",
        "data[\"cleaned_text\"] = data[\"text\"].apply(clean_text)\n",
        "\n",
        "# Convert labels to integers\n",
        "label_map = {\"positive\": 0, \"neutral\": 1, \"negative\": 2}\n",
        "data[\"label\"] = data[\"label\"].map(label_map)\n",
        "\n",
        "# Tokenize the cleaned text\n",
        "data['tokenized'] = data['cleaned_text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
        "\n",
        "# Pad or truncate to fixed length (e.g., 128 tokens)\n",
        "data['padded_tokenized'] = data['tokenized'].apply(\n",
        "    lambda x: x + [tokenizer.pad_token_id] * (128 - len(x)) if len(x) < 128 else x[:128]\n",
        ")\n",
        "\n",
        "# Preview cleaned and labeled data\n",
        "print(data[['cleaned_text', 'label', 'padded_tokenized']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "6ef4a344a9a048c29f3bc27c5a5f3923",
            "f42114124bd04f6685e069a2e829d133",
            "0844ea54f9e84392859e3f3ebfb71e12",
            "9eec86323fef41c494835ee9ee9525e2",
            "a816fa6b97b6457c8ea4068f19566051",
            "1d66b255751a4b018156e0cf53d5fe9b",
            "59186b48e3814d1199f15ab1b9f9db13",
            "fad2c37925494b92baf57bbf2eb3fddd",
            "992cd97758744f2c8945ac8c5a355021",
            "af400147eb50446a932fc2155c7f6c48",
            "73cfce04a75249268ad5c2ea051ec8aa",
            "554cd9f6026848abb9dacb01c7aa73ed",
            "1f5268ac8487491aa6f3aba35a7c9140",
            "61ffba101bd44e27abf95fe1c0f77396",
            "4e658e4362af4236a7a451a5c57f1174",
            "24880670b63440fbb0246f44cee3e5ae",
            "76ee31c3f7924a30aa5a15df6b16a510",
            "79b7ad507a9046c7ba4d44e9bcce99df",
            "3fb7c8a5dd8c475396223dd93078606b",
            "a3d1f7a11d6c4e7f9011df1a5d7ff9cc",
            "02f90eeb93c34b91908d78433c08c37d",
            "81daf79ecc654cd5aa28774dc9548873",
            "34855602bba6470087abca8d465e21c9",
            "e294b1cad12b4588a6bfed43c75ef70d",
            "992ad2dee69240d084f4014699115830",
            "b781345882dd4726addd7f89b7fc2858",
            "92dbf3794d68414cbb31e1ddc69fd0ca",
            "222b6c4c53d04a44895bf03911e1d6f4",
            "20e658c3b2ad4df6a2ea81bce043610e",
            "7267575a57e3424489660cb12b419d40",
            "8ee108cc5dbb4e3590c57da8f63834f9",
            "ab624aa559d244048fb98406bf89f90d",
            "fb43178a9fb54d98b2a4e7e1ee4aede5",
            "76962be368544ffcbe8e4757aedb958e",
            "51c64cd2b1944011a71d6510454617cd",
            "41c6c3ee44c148758a40f9feddc0efdd",
            "c9a85c2799fc4fab8aa99e8ab2455024",
            "9c52e3670ed44accbb5576ba6617d2bb",
            "5cb783189b2847a29366faa58ea4d440",
            "cb0e0093c72c493090769db173e169ba",
            "e8dbc52f19864cc69738d97b9ae06db4",
            "fde7aab093e54a48bf128125691ec26e",
            "93ae8790cf3e457fbba7ef64d2fc117f",
            "e15813723ddc419397a3a21033b9c905"
          ]
        },
        "id": "XmVAxnbuUemx",
        "outputId": "7fc05514-3398-4874-8376-7fc363febac3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ef4a344a9a048c29f3bc27c5a5f3923"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "554cd9f6026848abb9dacb01c7aa73ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34855602bba6470087abca8d465e21c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76962be368544ffcbe8e4757aedb958e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        cleaned_text  label  \\\n",
            "0  the staff was very kind and attentive to my needs      0   \n",
            "1  the waiting time was too long and the staff wa...      2   \n",
            "2  the doctor answered all my questionsbut the fa...      1   \n",
            "3  the nurse was compassionate made me feel comfo...      0   \n",
            "4  i had to wait over an hour before being seen u...      2   \n",
            "\n",
            "                                    padded_tokenized  \n",
            "0  [101, 1996, 3095, 2001, 2200, 2785, 1998, 2012...  \n",
            "1  [101, 1996, 3403, 2051, 2001, 2205, 2146, 1998...  \n",
            "2  [101, 1996, 3460, 4660, 2035, 2026, 3980, 8569...  \n",
            "3  [101, 1996, 6821, 2001, 29353, 2081, 2033, 251...  \n",
            "4  [101, 1045, 2018, 2000, 3524, 2058, 2019, 3178...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Step 2: Split the dataset</h3>"
      ],
      "metadata": {
        "id": "AtXK4AcdWZY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data: 70% training, 15% validation, 15% test\n",
        "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training Size: {len(train_data)}, Validation Size: {len(val_data)}, Test Size: {len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljGBwn8tWbJp",
        "outputId": "71c4332b-1b57-4bb3-9331-1b48af7f8e7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Size: 4, Validation Size: 1, Test Size: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Step 3: Set up the environment</h3>"
      ],
      "metadata": {
        "id": "x7RM9O19WvHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "# Convert DataFrame to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_data)\n",
        "val_dataset = Dataset.from_pandas(val_data)\n",
        "test_dataset = Dataset.from_pandas(test_data)\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"cleaned_text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "# Tokenize the dataset\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Remove unnecessary columns\n",
        "train_dataset = train_dataset.remove_columns([\"text\", \"cleaned_text\"])\n",
        "val_dataset = val_dataset.remove_columns([\"text\", \"cleaned_text\"])\n",
        "test_dataset = test_dataset.remove_columns([\"text\", \"cleaned_text\"])\n",
        "\n",
        "# Convert labels to int if they are not already\n",
        "train_dataset = train_dataset.map(lambda x: {\"label\": int(x[\"label\"])})\n",
        "val_dataset = val_dataset.map(lambda x: {\"label\": int(x[\"label\"])})\n",
        "test_dataset = test_dataset.map(lambda x: {\"label\": int(x[\"label\"])})\n",
        "\n",
        "# Print a sample to confirm input_ids exist\n",
        "print(train_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "ab1f8f59f75f417b83d532c448542b45",
            "258d76de80a9478694c3f7f2904adb14",
            "1555ac022bdc4bceaf621ca60cbc284f",
            "108383e4e2314139bdd5a61d3f21484a",
            "786a2e1f62a74621b3176a820b3a29b9",
            "72111afed616461b9a7afa34b7a650fc",
            "abed1a06b767458298f4839d3ab7e6d9",
            "0b702d39a5c342108dd88bd40884aca9",
            "a67b0e4226c643b98c8ea040ac696846",
            "95eb1566b9124e46b46cb9c43ac40733",
            "7ea7549666c345c5af5c1419531c5641",
            "fe82a797098e4de4b7a0709a6034e560",
            "0ca61d6cf2974ea4b92a2e8b58ebcd3a",
            "e16408f075734e4bbc2c28779eff46a9",
            "1dcd681b1ccc41daa7ccd1de03ec14ff",
            "8f8af59416ca4bc1a7e3ec4266089c45",
            "fbb64747c79b4f58881c4610d0af42d4",
            "5fa85b2c58484d2e84e4a0d59c969301",
            "db81b7debfec4711b876e8f51db01bb8",
            "1fdde513a3a347509a7b127248037c5e",
            "4e4a54570d444bda8bf4ea58b54aa4f2",
            "0b47fa6100d84de1b393eb137a69d105",
            "59501e268e3e453990fdf0687eab429f",
            "ef36d262743649afb455649ea9a84d2b",
            "f20eac89110a42b287d97095f3129dd6",
            "929f6a9e2ae44cb6aa48dd78073cc707",
            "ee00657d17be457bba072219dff8e4bb",
            "a1c51a767638433582bb1f2585e2aac8",
            "b4d97aa93bef4ede8c94d88604aa4d6f",
            "6c3d116abc1f4585bf9bcbb0cf91156d",
            "8801a2fcee0e45d9b2b47135c16a59f3",
            "08aae5cc1e584c6fa71ee565c4dc76db",
            "b524f121441c4d3a91275092713f5e27",
            "80ef0157cc4e4e2881dc4497bac66283",
            "df40c67e1a8f435ba5a115d755636a68",
            "fcc2afb841b344e994f0b48f61f4d8f3",
            "e3adc9759cea4b5c8c373024f065d13a",
            "13250429f05742d79cc3d8f43f54c08f",
            "10a86c2fe14d4a8f954b2a9e2436d8fe",
            "4652b449a8b249868d51d3d9c08502db",
            "6c8621d7f3aa4e04acb7c3379da31661",
            "92ad8bf26f9b4fa4b66bc4f2d2a06e14",
            "d2e6482cef1f4e1e91caa65889838e70",
            "20f81b7d7e1847cc9fa0e24773876da7",
            "19292fa31d084576b95f664c44ed9a63",
            "31b188f6a5ca4a9e9ab8d3a871b79410",
            "e7aa408fc7e24dcc97de991dc91e94ae",
            "5e73d32d60eb46bba7bec945c63f7bb6",
            "90c6f464218c4e1c9852059aa441e8cc",
            "347aa2531d5346bdbfbc74243b0d0761",
            "65843168b46b4b6da838d9769f1fd36e",
            "76e2270a376b44bcb1d33f3f50ca5438",
            "8b711e8b3fff4d95a98982b314723ee7",
            "67337913f3d84dd7a933f1a10a51c943",
            "2243b519949e4a8ca05807e79c15e9fd",
            "2f1b17d1792447d0b31a77a00db57b7d",
            "4a8a249ab85744d7bf69c49095c1e7b3",
            "11b5ab5035e1447d83516160ea9ae730",
            "f84e33574cc647f7b1dd44aeb38aa1b2",
            "d8fa3e6cc8c04c7db20ff47f9f43e530",
            "9a3b5681bdb04c298a143358d614eab2",
            "4d08180ea128401b8cafe93ff8344cca",
            "33baac9a93764610ba01dd7426398813",
            "8c51658835624f1ea77679ea8f16d238",
            "f43cc927e7c741c0bb00f61fd4533767",
            "cb5ff6d202ec47b6b9e83cad8bbd77c8"
          ]
        },
        "id": "XI21yIKCWwl4",
        "outputId": "b4e275d1-92d6-4cf4-fedc-e781e3a3ae87"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab1f8f59f75f417b83d532c448542b45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe82a797098e4de4b7a0709a6034e560"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59501e268e3e453990fdf0687eab429f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80ef0157cc4e4e2881dc4497bac66283"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19292fa31d084576b95f664c44ed9a63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f1b17d1792447d0b31a77a00db57b7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 1, 'tokenized': [101, 1996, 3460, 4660, 2035, 2026, 3980, 8569, 2102, 1996, 4322, 2001, 25963, 102], 'padded_tokenized': [101, 1996, 3460, 4660, 2035, 2026, 3980, 8569, 2102, 1996, 4322, 2001, 25963, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '__index_level_0__': 2, 'input_ids': [101, 1996, 3460, 4660, 2035, 2026, 3980, 8569, 2102, 1996, 4322, 2001, 25963, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Step 4: Configure hyperparameters</h3>"
      ],
      "metadata": {
        "id": "Q6KHbTupXfMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# Load pre-trained BERT model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    output_dir='./results',\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "# **Explain 'eval_strategy':**\n",
        "# This determines when the model is evaluated. 'Epoch' evaluates the model after each training epoch."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxu_RuPPXgsB",
        "outputId": "ca36b8b4-c2e1-42ef-be29-dfd0edc85819"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Step 5: Fine-tune the model</h3>"
      ],
      "metadata": {
        "id": "Wy-IithmYOa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]),\n",
        "    eval_dataset=val_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "VEBDFw3dYP4j",
        "outputId": "c42963a0-47d5-4bbc-e05e-d30e53d0061f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mscientistamzad786\u001b[0m (\u001b[33mscientistamzad786-jamia-millia-islamia\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251014_154415-uwnwvphj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/scientistamzad786-jamia-millia-islamia/huggingface/runs/uwnwvphj' target=\"_blank\">youthful-cloud-1</a></strong> to <a href='https://wandb.ai/scientistamzad786-jamia-millia-islamia/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/scientistamzad786-jamia-millia-islamia/huggingface' target=\"_blank\">https://wandb.ai/scientistamzad786-jamia-millia-islamia/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/scientistamzad786-jamia-millia-islamia/huggingface/runs/uwnwvphj' target=\"_blank\">https://wandb.ai/scientistamzad786-jamia-millia-islamia/huggingface/runs/uwnwvphj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 01:32, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.140300</td>\n",
              "      <td>0.711755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.032900</td>\n",
              "      <td>0.758072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.027000</td>\n",
              "      <td>0.780898</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3, training_loss=1.0667176246643066, metrics={'train_runtime': 327.1506, 'train_samples_per_second': 0.037, 'train_steps_per_second': 0.009, 'total_flos': 789340253184.0, 'train_loss': 1.0667176246643066, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Step 6: Evaluate the model</h3>"
      ],
      "metadata": {
        "id": "Qd4rcI01Yd1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Generate predictions\n",
        "test_dataset = test_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = predictions.predictions.argmax(-1)\n",
        "labels = test_dataset[\"label\"]\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(labels, preds)\n",
        "f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy}, F1 Score: {f1}\")\n",
        "\n",
        "# **Explain metric importance**:\n",
        "# High F1 scores indicate balanced performance across all classes, crucial in tasks like sentiment analysis."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "uWHogbeeYfNv",
        "outputId": "9e27c39a-66d6-4667-8323-eb97091f24e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0, F1 Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Step 7: Deploy the model</h3>"
      ],
      "metadata": {
        "id": "G2vcQcJDZoGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save_pretrained(\"./fine_tuned_bert\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_bert\")\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmqufNlGZln8",
        "outputId": "35e1c7da-36dd-42f7-c0cb-b5d402b4ff1c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    }
  ]
}
