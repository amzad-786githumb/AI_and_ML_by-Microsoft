{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amzad-786githumb/AI_and_ML_by-Microsoft/blob/main/32__Integrating_NLP_components.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svQneDrzshXF"
      },
      "source": [
        "<h2>Tasks:</h2>\n",
        "* Understand how to integrate various NLP components.\n",
        "* Build a system that processes text through multiple NLP tasks.\n",
        "* Test the system with sample text to evaluate the performance of each component."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxJOPPIds7ZF"
      },
      "source": [
        "<h3>Step 1: Set up the environment</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pho9SUn0srjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1cf586-e6ff-4e47-a518-28738260f5eb"
      },
      "execution_count": 2,
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install nltk\n",
        "!pip install spacy\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_v_JTXxtxuT"
      },
      "source": [
        "<h3>Step 2: Preprocess the text with tokenization</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtY4ugFMQxNV"
      },
      "execution_count": 3,
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Natural Language Processing is transforming AI applications.\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7Vxbp3duQ5I"
      },
      "source": [
        "<h3>Step 3: Apply POS tagging</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssKrZOMHydTc"
      },
      "execution_count": 4,
      "outputs": [],
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "tagged_tokens = nltk.pos_tag(tokens)\n",
        "print(tagged_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8zSN47Ou1_D"
      },
      "source": [
        "<h3>Step 4: Perform NER</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z-t49B1ut_9"
      },
      "execution_count": 5,
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrdwNsP-vUOi"
      },
      "source": [
        "<h3>Step 5: Apply sentiment analysis</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq_6QwevvCtc"
      },
      "execution_count": 6,
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "sentiment_analyzer = pipeline('sentiment-analysis')\n",
        "result = sentiment_analyzer(text)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgGhgAMx_sx_"
      },
      "source": [
        "<h3>Step 6: Test the integrated system</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0-qO8NKADvO"
      },
      "source": [
        "**Input text:** \"Serena Williams won Wimbledon in 2016, solidifying her status as one of the greatest tennis players in history.\"\n",
        "\n",
        "* **Tokenization output:** [\"Serena\", \"Williams\", \"won\", \"Wimbledon\", \"in\", \"2016\", \"...\"]\n",
        "* **POS tagging output:** [('Serena', 'NNP'), ('Williams', 'NNP'), ('won', 'VBD'), ...]\n",
        "* **NER output:** \"Serena Williams\" (Person), \"Wimbledon\" (Location), \"2016\" (Date)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMu+gIXDdMWxAyk3g5GRrZw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
